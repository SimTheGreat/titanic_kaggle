{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d097018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04bc3453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier.csv          submission.csv\n",
      "Untitled.ipynb                      submission_LogisticRegressuion.csv\n",
      "ensemble.csv                        test.csv\n",
      "gender_submission.csv               train.csv\n",
      "notebook.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef24299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686a5ebf",
   "metadata": {},
   "source": [
    "<center> <h1> data description</h1></center>\n",
    "\n",
    "\n",
    "\n",
    "| Column    | Description                                      | Values                                |\n",
    "|-----------|--------------------------------------------------|---------------------------------------|\n",
    "| survival  | Survival                                        | 0 = No, 1 = Yes                      |\n",
    "| pclass    | Ticket class                                    | 1 = 1st, 2 = 2nd, 3 = 3rd            |\n",
    "| sex       | Sex                                            | Male / Female                        |\n",
    "| age       | Age in years                                   | Numeric                              |\n",
    "| sibsp     | # of siblings/spouses aboard the Titanic       | Numeric                              |\n",
    "| parch     | # of parents/children aboard the Titanic       | Numeric                              |\n",
    "| ticket    | Ticket number                                  | Alphanumeric                         |\n",
    "| fare      | Passenger fare                                 | Numeric                              |\n",
    "| cabin     | Cabin number                                   | Alphanumeric                         |\n",
    "| embarked  | Port of Embarkation                            | C = Cherbourg, Q = Queenstown, S = Southampton |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e08fa82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd57752c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6dff349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 54.,  46., 177., 169., 118.,  70.,  45.,  24.,   9.,   2.]),\n",
       " array([ 0.42 ,  8.378, 16.336, 24.294, 32.252, 40.21 , 48.168, 56.126,\n",
       "        64.084, 72.042, 80.   ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fill nan's\n",
    "#lets start with age but fill with mean or median?\n",
    "plt.hist(train_df.Age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "963a84f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/lpfts5xj4k9dqx96kbpbcclc0000gn/T/ipykernel_6363/2935857203.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[\"Age\"].fillna(train_df[\"Age\"].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_df[\"Age\"].fillna(train_df[\"Age\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a1a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     889\n",
       "unique      3\n",
       "top         S\n",
       "freq      644\n",
       "Name: Embarked, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Embarked\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845717b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c2ea07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'S': 644, 'C': 168, 'Q': 77, nan: 2})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_df[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "763de1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/lpfts5xj4k9dqx96kbpbcclc0000gn/T/ipykernel_6363/2115593368.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df[\"Embarked\"].fillna(\"S\", inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_df[\"Embarked\"].fillna(\"S\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79d55a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'S': 646, 'C': 168, 'Q': 77})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(train_df[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11aa8859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C85\n",
      "1\n",
      "C123\n",
      "1\n",
      "E46\n",
      "0\n",
      "G6\n",
      "1\n",
      "C103\n",
      "1\n",
      "D56\n",
      "1\n",
      "A6\n",
      "1\n",
      "C23 C25 C27\n",
      "0\n",
      "B78\n",
      "1\n",
      "D33\n",
      "1\n",
      "B30\n",
      "0\n",
      "C52\n",
      "1\n",
      "B28\n",
      "1\n",
      "C83\n",
      "0\n",
      "F33\n",
      "1\n",
      "F G73\n",
      "0\n",
      "C23 C25 C27\n",
      "1\n",
      "E31\n",
      "0\n",
      "A5\n",
      "0\n",
      "D10 D12\n",
      "1\n",
      "D26\n",
      "0\n",
      "C110\n",
      "0\n",
      "B58 B60\n",
      "0\n",
      "E101\n",
      "1\n",
      "D26\n",
      "0\n",
      "F E69\n",
      "1\n",
      "D47\n",
      "1\n",
      "C123\n",
      "0\n",
      "B86\n",
      "0\n",
      "F2\n",
      "0\n",
      "C2\n",
      "1\n",
      "E33\n",
      "1\n",
      "B19\n",
      "0\n",
      "A7\n",
      "0\n",
      "C49\n",
      "0\n",
      "F4\n",
      "1\n",
      "A32\n",
      "0\n",
      "F2\n",
      "1\n",
      "B4\n",
      "1\n",
      "B80\n",
      "1\n",
      "G6\n",
      "0\n",
      "A31\n",
      "1\n",
      "D36\n",
      "1\n",
      "D15\n",
      "1\n",
      "C93\n",
      "1\n",
      "C83\n",
      "1\n",
      "C78\n",
      "0\n",
      "D35\n",
      "1\n",
      "G6\n",
      "0\n",
      "C87\n",
      "0\n",
      "B77\n",
      "1\n",
      "E67\n",
      "0\n",
      "B94\n",
      "0\n",
      "C125\n",
      "1\n",
      "C99\n",
      "1\n",
      "C118\n",
      "0\n",
      "D7\n",
      "1\n",
      "A19\n",
      "0\n",
      "B49\n",
      "1\n",
      "D\n",
      "0\n",
      "C22 C26\n",
      "0\n",
      "C106\n",
      "1\n",
      "B58 B60\n",
      "1\n",
      "E101\n",
      "1\n",
      "C22 C26\n",
      "1\n",
      "C65\n",
      "1\n",
      "E36\n",
      "1\n",
      "C54\n",
      "1\n",
      "B57 B59 B63 B66\n",
      "1\n",
      "C7\n",
      "1\n",
      "E34\n",
      "1\n",
      "C32\n",
      "1\n",
      "D\n",
      "1\n",
      "B18\n",
      "1\n",
      "C124\n",
      "0\n",
      "C91\n",
      "0\n",
      "C2\n",
      "0\n",
      "E40\n",
      "1\n",
      "T\n",
      "0\n",
      "F2\n",
      "1\n",
      "C23 C25 C27\n",
      "1\n",
      "F33\n",
      "1\n",
      "C128\n",
      "0\n",
      "E33\n",
      "1\n",
      "D37\n",
      "1\n",
      "B35\n",
      "1\n",
      "E50\n",
      "1\n",
      "C82\n",
      "0\n",
      "B96 B98\n",
      "1\n",
      "D36\n",
      "1\n",
      "G6\n",
      "1\n",
      "C78\n",
      "1\n",
      "E10\n",
      "1\n",
      "C52\n",
      "1\n",
      "E44\n",
      "0\n",
      "B96 B98\n",
      "1\n",
      "C23 C25 C27\n",
      "0\n",
      "A34\n",
      "1\n",
      "C104\n",
      "1\n",
      "C111\n",
      "0\n",
      "C92\n",
      "1\n",
      "E38\n",
      "0\n",
      "D21\n",
      "1\n",
      "E12\n",
      "1\n",
      "E63\n",
      "0\n",
      "D\n",
      "1\n",
      "A14\n",
      "0\n",
      "B49\n",
      "1\n",
      "C93\n",
      "1\n",
      "B37\n",
      "0\n",
      "C30\n",
      "0\n",
      "D20\n",
      "1\n",
      "C22 C26\n",
      "0\n",
      "B79\n",
      "1\n",
      "C65\n",
      "0\n",
      "E25\n",
      "1\n",
      "D46\n",
      "0\n",
      "F33\n",
      "1\n",
      "B73\n",
      "1\n",
      "B18\n",
      "1\n",
      "C95\n",
      "0\n",
      "B38\n",
      "0\n",
      "B39\n",
      "1\n",
      "B22\n",
      "1\n",
      "C86\n",
      "0\n",
      "C70\n",
      "1\n",
      "A16\n",
      "1\n",
      "E67\n",
      "1\n",
      "C101\n",
      "1\n",
      "E25\n",
      "1\n",
      "E44\n",
      "1\n",
      "C68\n",
      "1\n",
      "A10\n",
      "0\n",
      "E68\n",
      "1\n",
      "B41\n",
      "1\n",
      "D20\n",
      "1\n",
      "A20\n",
      "1\n",
      "C125\n",
      "1\n",
      "F4\n",
      "1\n",
      "D19\n",
      "1\n",
      "D50\n",
      "0\n",
      "D9\n",
      "1\n",
      "A23\n",
      "1\n",
      "B50\n",
      "1\n",
      "B35\n",
      "1\n",
      "D33\n",
      "1\n",
      "A26\n",
      "1\n",
      "D48\n",
      "0\n",
      "E58\n",
      "0\n",
      "C126\n",
      "1\n",
      "B71\n",
      "0\n",
      "B51 B53 B55\n",
      "1\n",
      "D49\n",
      "1\n",
      "B5\n",
      "1\n",
      "B20\n",
      "1\n",
      "C68\n",
      "0\n",
      "F G63\n",
      "0\n",
      "C62 C64\n",
      "1\n",
      "E24\n",
      "1\n",
      "E24\n",
      "1\n",
      "C90\n",
      "1\n",
      "C124\n",
      "0\n",
      "C126\n",
      "1\n",
      "F G73\n",
      "0\n",
      "C45\n",
      "1\n",
      "E101\n",
      "1\n",
      "E8\n",
      "1\n",
      "B5\n",
      "1\n",
      "B101\n",
      "1\n",
      "D45\n",
      "1\n",
      "C46\n",
      "0\n",
      "B57 B59 B63 B66\n",
      "1\n",
      "B22\n",
      "0\n",
      "D30\n",
      "0\n",
      "E121\n",
      "1\n",
      "B77\n",
      "1\n",
      "B96 B98\n",
      "1\n",
      "D11\n",
      "1\n",
      "E77\n",
      "0\n",
      "F38\n",
      "0\n",
      "B3\n",
      "1\n",
      "B20\n",
      "1\n",
      "D6\n",
      "0\n",
      "B82 B84\n",
      "0\n",
      "D17\n",
      "1\n",
      "B96 B98\n",
      "1\n",
      "A36\n",
      "0\n",
      "E8\n",
      "1\n",
      "B102\n",
      "0\n",
      "B69\n",
      "1\n",
      "E121\n",
      "1\n",
      "B28\n",
      "1\n",
      "E49\n",
      "1\n",
      "C47\n",
      "1\n",
      "C92\n",
      "1\n",
      "D28\n",
      "1\n",
      "E17\n",
      "1\n",
      "D17\n",
      "1\n",
      "A24\n",
      "0\n",
      "D35\n",
      "1\n",
      "B51 B53 B55\n",
      "0\n",
      "C50\n",
      "1\n",
      "B42\n",
      "1\n",
      "C148\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "count=[]\n",
    "sur=[]\n",
    "for i in train_df[train_df['Cabin'].notna()].index:\n",
    "        print( train_df.Cabin[i])\n",
    "        print( train_df.Survived[i])\n",
    "        count.append(train_df.Cabin[i][0])\n",
    "        sur.append(train_df.Survived[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bad25f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/lpfts5xj4k9dqx96kbpbcclc0000gn/T/ipykernel_6363/3493730914.py:4: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  sns.barplot(x=df['Cabin_Letter'], y=df['Survived'], ci=None, order=sorted(df['Cabin_Letter'].unique()))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Cabin_Letter', ylabel='Survived'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Survived': sur, 'Cabin_Letter': count})\n",
    "\n",
    "\n",
    "sns.barplot(x=df['Cabin_Letter'], y=df['Survived'], ci=None, order=sorted(df['Cabin_Letter'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b389ff9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aa8cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Sex'] = train_df['Sex'].map({'female': 1, 'male': 0})\n",
    "\n",
    "train_df['Embarked'] = train_df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ae54127",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['Name', 'Ticket', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0485803f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived       1.000000\n",
      "Sex            0.543351\n",
      "Fare           0.257307\n",
      "Parch          0.081629\n",
      "PassengerId   -0.005007\n",
      "SibSp         -0.035322\n",
      "Age           -0.064910\n",
      "Embarked      -0.167675\n",
      "Pclass        -0.338481\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "correlation = train_df.corr()['Survived'].sort_values(ascending=False)\n",
    "\n",
    "# Display correlation values\n",
    "print(correlation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c54ca",
   "metadata": {},
   "source": [
    "1 perfect positiv corolation\n",
    "0 no corrolation\n",
    "-1 perfect negativ corrolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5541dd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0              1         0       3    0  22.0      1      0   7.2500         2\n",
       "1              2         1       1    1  38.0      1      0  71.2833         0\n",
       "2              3         1       3    1  26.0      0      0   7.9250         2\n",
       "3              4         1       1    1  35.0      1      0  53.1000         2\n",
       "4              5         0       3    0  35.0      0      0   8.0500         2\n",
       "..           ...       ...     ...  ...   ...    ...    ...      ...       ...\n",
       "886          887         0       2    0  27.0      0      0  13.0000         2\n",
       "887          888         1       1    1  19.0      0      0  30.0000         2\n",
       "888          889         0       3    1  28.0      1      2  23.4500         2\n",
       "889          890         1       1    0  26.0      0      0  30.0000         0\n",
       "890          891         0       3    0  32.0      0      0   7.7500         1\n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1419d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be996b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/lpfts5xj4k9dqx96kbpbcclc0000gn/T/ipykernel_6363/482392045.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Age'].fillna(test_df['Age'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_df['Sex'] = test_df['Sex'].map({'female': 1, 'male': 0})\n",
    "\n",
    "test_df['Embarked'] = test_df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "test_df = test_df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "test_df['Age'].fillna(test_df['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d37329e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dd/lpfts5xj4k9dqx96kbpbcclc0000gn/T/ipykernel_6363/4271572204.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "993a1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['Survived'])\n",
    "y_train = train_df['Survived']\n",
    "\n",
    "X_test = test_df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50e12cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad7fb013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Pclass         0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f36c3ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked\n",
       "0            892       3    0  34.5      0      0    7.8292         1\n",
       "1            893       3    1  47.0      1      0    7.0000         2\n",
       "2            894       2    0  62.0      0      0    9.6875         1\n",
       "3            895       3    0  27.0      0      0    8.6625         2\n",
       "4            896       3    1  22.0      1      1   12.2875         2\n",
       "..           ...     ...  ...   ...    ...    ...       ...       ...\n",
       "413         1305       3    0  27.0      0      0    8.0500         2\n",
       "414         1306       1    1  39.0      0      0  108.9000         0\n",
       "415         1307       3    0  38.5      0      0    7.2500         2\n",
       "416         1308       3    0  27.0      0      0    8.0500         2\n",
       "417         1309       3    0  27.0      1      1   22.3583         0\n",
       "\n",
       "[418 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4adb280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/livemea-env/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4213a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea04f3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived':y_pred})\n",
    "out.to_csv('submission_LogisticRegressuion.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "095bcd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier.csv          submission.csv\r\n",
      "Untitled.ipynb                      submission_LogisticRegressuion.csv\r\n",
      "ensemble.csv                        test.csv\r\n",
      "gender_submission.csv               train.csv\r\n",
      "notebook.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8afc3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = dt.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b7b48c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f7b9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived':y_pred})\n",
    "out.to_csv('DecisionTreeClassifier.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6d94758",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, GradientBoostingClassifier\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m      7\u001b[0m base_models \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)),\n\u001b[1;32m      9\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgb\u001b[39m\u001b[38;5;124m'\u001b[39m, GradientBoostingClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)),\n\u001b[1;32m     10\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m))\n\u001b[1;32m     11\u001b[0m ]\n\u001b[1;32m     14\u001b[0m stack_model \u001b[38;5;241m=\u001b[39m StackingClassifier(estimators\u001b[38;5;241m=\u001b[39mbase_models, final_estimator\u001b[38;5;241m=\u001b[39mLogisticRegression())\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "base_models = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=200, learning_rate=0.1)),\n",
    "    ('xgb', xgb.XGBClassifier(n_estimators=200, learning_rate=0.1))\n",
    "]\n",
    "\n",
    "\n",
    "stack_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression())\n",
    "\n",
    "\n",
    "stack_model.fit(X_train, y_train)\n",
    "y_pred = stack_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e902f2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2592a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived':y_pred})\n",
    "out.to_csv('ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0799e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6afa20f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/livemea-env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 0.4468 - loss: 11.9895 \n",
      "Epoch 2/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.3247 - loss: 5.0352\n",
      "Epoch 3/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.4556 - loss: 2.2337\n",
      "Epoch 4/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.5506 - loss: 1.2699\n",
      "Epoch 5/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.6521 - loss: 0.7474\n",
      "Epoch 6/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.6496 - loss: 0.8040\n",
      "Epoch 7/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.6863 - loss: 0.7374\n",
      "Epoch 8/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.6573 - loss: 0.7307\n",
      "Epoch 9/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.6953 - loss: 0.6216\n",
      "Epoch 10/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.6762 - loss: 0.7316\n",
      "Epoch 11/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.6904 - loss: 0.6878\n",
      "Epoch 12/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.7183 - loss: 0.6180\n",
      "Epoch 13/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7041 - loss: 0.5760\n",
      "Epoch 14/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7315 - loss: 0.6034\n",
      "Epoch 15/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.6705 - loss: 0.6580\n",
      "Epoch 16/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.7114 - loss: 0.6337\n",
      "Epoch 17/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7112 - loss: 0.6214\n",
      "Epoch 18/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7087 - loss: 0.6068\n",
      "Epoch 19/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7305 - loss: 0.5808\n",
      "Epoch 20/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7401 - loss: 0.5901\n",
      "Epoch 21/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.7226 - loss: 0.5962\n",
      "Epoch 22/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7551 - loss: 0.5432\n",
      "Epoch 23/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7569 - loss: 0.5247\n",
      "Epoch 24/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7182 - loss: 0.5853\n",
      "Epoch 25/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7262 - loss: 0.5861\n",
      "Epoch 26/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7417 - loss: 0.5737\n",
      "Epoch 27/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7593 - loss: 0.5354\n",
      "Epoch 28/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7589 - loss: 0.5424\n",
      "Epoch 29/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7757 - loss: 0.5080\n",
      "Epoch 30/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7732 - loss: 0.5010\n",
      "Epoch 31/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7287 - loss: 0.5782\n",
      "Epoch 32/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7034 - loss: 0.6059\n",
      "Epoch 33/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7712 - loss: 0.5366\n",
      "Epoch 34/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7346 - loss: 0.6409\n",
      "Epoch 35/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7566 - loss: 0.5114\n",
      "Epoch 36/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7706 - loss: 0.4850\n",
      "Epoch 37/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.8034 - loss: 0.4631\n",
      "Epoch 38/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - accuracy: 0.7922 - loss: 0.4786\n",
      "Epoch 39/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.6979 - loss: 0.6852\n",
      "Epoch 40/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7841 - loss: 0.4880\n",
      "Epoch 41/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7520 - loss: 0.5561\n",
      "Epoch 42/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7818 - loss: 0.4848\n",
      "Epoch 43/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7456 - loss: 0.5631\n",
      "Epoch 44/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7101 - loss: 0.7020\n",
      "Epoch 45/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7767 - loss: 0.5069\n",
      "Epoch 46/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7750 - loss: 0.5012\n",
      "Epoch 47/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.6915 - loss: 0.6172\n",
      "Epoch 48/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7760 - loss: 0.4729\n",
      "Epoch 49/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7881 - loss: 0.4749\n",
      "Epoch 50/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.8098 - loss: 0.4832\n",
      "Epoch 51/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.7790 - loss: 0.4933\n",
      "Epoch 52/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7573 - loss: 0.5356\n",
      "Epoch 53/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7817 - loss: 0.4883\n",
      "Epoch 54/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7843 - loss: 0.5035\n",
      "Epoch 55/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7693 - loss: 0.5223\n",
      "Epoch 56/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.7696 - loss: 0.5123\n",
      "Epoch 57/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7761 - loss: 0.4867\n",
      "Epoch 58/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7744 - loss: 0.5101\n",
      "Epoch 59/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7902 - loss: 0.4702\n",
      "Epoch 60/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7907 - loss: 0.4766\n",
      "Epoch 61/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7810 - loss: 0.5032\n",
      "Epoch 62/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7755 - loss: 0.4689\n",
      "Epoch 63/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7898 - loss: 0.4805\n",
      "Epoch 64/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7782 - loss: 0.5094\n",
      "Epoch 65/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7813 - loss: 0.5078\n",
      "Epoch 66/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7941 - loss: 0.5077\n",
      "Epoch 67/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7950 - loss: 0.4629\n",
      "Epoch 68/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.8013 - loss: 0.4809\n",
      "Epoch 69/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7599 - loss: 0.5223\n",
      "Epoch 70/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - accuracy: 0.8150 - loss: 0.4559\n",
      "Epoch 71/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7902 - loss: 0.4715\n",
      "Epoch 72/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7819 - loss: 0.4656\n",
      "Epoch 73/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7732 - loss: 0.5162\n",
      "Epoch 74/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7913 - loss: 0.4894\n",
      "Epoch 75/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7566 - loss: 0.5677\n",
      "Epoch 76/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7958 - loss: 0.5054\n",
      "Epoch 77/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.8079 - loss: 0.4713\n",
      "Epoch 78/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7882 - loss: 0.4778\n",
      "Epoch 79/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.7794 - loss: 0.4858\n",
      "Epoch 80/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.7708 - loss: 0.5091\n",
      "Epoch 81/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8032 - loss: 0.4779\n",
      "Epoch 82/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7914 - loss: 0.4384\n",
      "Epoch 83/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7843 - loss: 0.4877\n",
      "Epoch 84/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7632 - loss: 0.5635\n",
      "Epoch 85/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7762 - loss: 0.4994\n",
      "Epoch 86/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.7917 - loss: 0.4500\n",
      "Epoch 87/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7908 - loss: 0.4834\n",
      "Epoch 88/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.7699 - loss: 0.4914\n",
      "Epoch 89/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7626 - loss: 0.5574\n",
      "Epoch 90/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7716 - loss: 0.5106\n",
      "Epoch 91/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7701 - loss: 0.5130\n",
      "Epoch 92/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.8003 - loss: 0.4567\n",
      "Epoch 93/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8053 - loss: 0.4367\n",
      "Epoch 94/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7742 - loss: 0.4884\n",
      "Epoch 95/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.7952 - loss: 0.4999\n",
      "Epoch 96/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.8001 - loss: 0.4599\n",
      "Epoch 97/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7914 - loss: 0.4998\n",
      "Epoch 98/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.7684 - loss: 0.4877\n",
      "Epoch 99/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7891 - loss: 0.4877\n",
      "Epoch 100/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7900 - loss: 0.4665\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb76ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=16, verbose=1)\n",
    "\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92aa9ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived':y_pred.flatten()})\n",
    "out.to_csv('model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8971d06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dea15eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/livemea-env/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.4495 - loss: 0.8873 \n",
      "Epoch 2/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - accuracy: 0.5197 - loss: 0.7409\n",
      "Epoch 3/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.5634 - loss: 0.7155\n",
      "Epoch 4/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.6248 - loss: 0.6702\n",
      "Epoch 5/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.6087 - loss: 0.6752\n",
      "Epoch 6/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.6271 - loss: 0.6415\n",
      "Epoch 7/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.6753 - loss: 0.6323\n",
      "Epoch 8/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.6686 - loss: 0.6319\n",
      "Epoch 9/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.6784 - loss: 0.6297\n",
      "Epoch 10/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.6296 - loss: 0.6421\n",
      "Epoch 11/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.6603 - loss: 0.6203\n",
      "Epoch 12/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.6763 - loss: 0.6257\n",
      "Epoch 13/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.6761 - loss: 0.6383\n",
      "Epoch 14/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.6625 - loss: 0.6154\n",
      "Epoch 15/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.6567 - loss: 0.6141\n",
      "Epoch 16/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.6646 - loss: 0.6262\n",
      "Epoch 17/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.6587 - loss: 0.6289\n",
      "Epoch 18/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.6790 - loss: 0.6062\n",
      "Epoch 19/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.6588 - loss: 0.6349\n",
      "Epoch 20/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.6549 - loss: 0.6061\n",
      "Epoch 21/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.7015 - loss: 0.5987\n",
      "Epoch 22/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.6592 - loss: 0.6113\n",
      "Epoch 23/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.6649 - loss: 0.6283\n",
      "Epoch 24/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.6810 - loss: 0.6107\n",
      "Epoch 25/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.6972 - loss: 0.5954\n",
      "Epoch 26/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 0.6525 - loss: 0.6191\n",
      "Epoch 27/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.6980 - loss: 0.6035\n",
      "Epoch 28/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.6800 - loss: 0.6086\n",
      "Epoch 29/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.6985 - loss: 0.5724\n",
      "Epoch 30/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.6732 - loss: 0.6116\n",
      "Epoch 31/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.6986 - loss: 0.5819\n",
      "Epoch 32/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7031 - loss: 0.5772\n",
      "Epoch 33/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7129 - loss: 0.5809\n",
      "Epoch 34/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.6611 - loss: 0.6042\n",
      "Epoch 35/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.6681 - loss: 0.5947\n",
      "Epoch 36/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.6851 - loss: 0.5914\n",
      "Epoch 37/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7128 - loss: 0.5580\n",
      "Epoch 38/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.6914 - loss: 0.5942\n",
      "Epoch 39/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.6742 - loss: 0.5922\n",
      "Epoch 40/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7129 - loss: 0.5640\n",
      "Epoch 41/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7121 - loss: 0.5824\n",
      "Epoch 42/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7018 - loss: 0.5466\n",
      "Epoch 43/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.6955 - loss: 0.6003\n",
      "Epoch 44/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7505 - loss: 0.5233\n",
      "Epoch 45/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7623 - loss: 0.5245\n",
      "Epoch 46/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 0.7544 - loss: 0.5297\n",
      "Epoch 47/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7198 - loss: 0.5548\n",
      "Epoch 48/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7419 - loss: 0.5251\n",
      "Epoch 49/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7574 - loss: 0.5044\n",
      "Epoch 50/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7498 - loss: 0.5337\n",
      "Epoch 51/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7584 - loss: 0.5158\n",
      "Epoch 52/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.7093 - loss: 0.5462\n",
      "Epoch 53/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7392 - loss: 0.5299\n",
      "Epoch 54/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7557 - loss: 0.5040\n",
      "Epoch 55/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7605 - loss: 0.4884\n",
      "Epoch 56/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7621 - loss: 0.5120\n",
      "Epoch 57/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7631 - loss: 0.5018\n",
      "Epoch 58/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7350 - loss: 0.5518\n",
      "Epoch 59/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7283 - loss: 0.5443\n",
      "Epoch 60/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7349 - loss: 0.5080\n",
      "Epoch 61/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7501 - loss: 0.5057\n",
      "Epoch 62/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7639 - loss: 0.4924\n",
      "Epoch 63/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7677 - loss: 0.5116\n",
      "Epoch 64/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7533 - loss: 0.5137\n",
      "Epoch 65/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7717 - loss: 0.4884\n",
      "Epoch 66/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7439 - loss: 0.5337\n",
      "Epoch 67/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7812 - loss: 0.4913\n",
      "Epoch 68/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7366 - loss: 0.5478\n",
      "Epoch 69/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.7535 - loss: 0.5158\n",
      "Epoch 70/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7305 - loss: 0.5302\n",
      "Epoch 71/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7363 - loss: 0.5453\n",
      "Epoch 72/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7592 - loss: 0.4927\n",
      "Epoch 73/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.7448 - loss: 0.5348\n",
      "Epoch 74/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 0.7151 - loss: 0.5374\n",
      "Epoch 75/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.7683 - loss: 0.4964\n",
      "Epoch 76/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.7346 - loss: 0.5338\n",
      "Epoch 77/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7650 - loss: 0.4956\n",
      "Epoch 78/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7711 - loss: 0.4988\n",
      "Epoch 79/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7386 - loss: 0.5340\n",
      "Epoch 80/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7457 - loss: 0.5153\n",
      "Epoch 81/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7397 - loss: 0.5183\n",
      "Epoch 82/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7655 - loss: 0.5126\n",
      "Epoch 83/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7601 - loss: 0.5000\n",
      "Epoch 84/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7149 - loss: 0.5561\n",
      "Epoch 85/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7296 - loss: 0.5393\n",
      "Epoch 86/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7386 - loss: 0.5302\n",
      "Epoch 87/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7566 - loss: 0.5076\n",
      "Epoch 88/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7583 - loss: 0.4959\n",
      "Epoch 89/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7506 - loss: 0.5136\n",
      "Epoch 90/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7544 - loss: 0.5012\n",
      "Epoch 91/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7988 - loss: 0.4846\n",
      "Epoch 92/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7504 - loss: 0.5192\n",
      "Epoch 93/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7605 - loss: 0.4972\n",
      "Epoch 94/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7510 - loss: 0.5178\n",
      "Epoch 95/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7872 - loss: 0.4724\n",
      "Epoch 96/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7372 - loss: 0.5225\n",
      "Epoch 97/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7816 - loss: 0.4710\n",
      "Epoch 98/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7542 - loss: 0.5102\n",
      "Epoch 99/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7646 - loss: 0.5156\n",
      "Epoch 100/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7768 - loss: 0.5046\n",
      "Epoch 101/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.7493 - loss: 0.5039\n",
      "Epoch 102/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7912 - loss: 0.5028\n",
      "Epoch 103/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7533 - loss: 0.5316\n",
      "Epoch 104/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7760 - loss: 0.4772\n",
      "Epoch 105/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7638 - loss: 0.5025\n",
      "Epoch 106/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7462 - loss: 0.5176\n",
      "Epoch 107/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7182 - loss: 0.5374\n",
      "Epoch 108/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7440 - loss: 0.5346\n",
      "Epoch 109/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7864 - loss: 0.4887\n",
      "Epoch 110/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7618 - loss: 0.5198\n",
      "Epoch 111/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7753 - loss: 0.4871\n",
      "Epoch 112/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7471 - loss: 0.5234\n",
      "Epoch 113/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7755 - loss: 0.4881\n",
      "Epoch 114/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7293 - loss: 0.5110\n",
      "Epoch 115/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7695 - loss: 0.4965\n",
      "Epoch 116/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7318 - loss: 0.5301\n",
      "Epoch 117/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7264 - loss: 0.5542\n",
      "Epoch 118/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7892 - loss: 0.4625\n",
      "Epoch 119/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7660 - loss: 0.4990\n",
      "Epoch 120/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7609 - loss: 0.5160\n",
      "Epoch 121/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7536 - loss: 0.4851\n",
      "Epoch 122/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7540 - loss: 0.5138\n",
      "Epoch 123/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7678 - loss: 0.4934\n",
      "Epoch 124/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 0.8004 - loss: 0.4957\n",
      "Epoch 125/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7719 - loss: 0.4980\n",
      "Epoch 126/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7561 - loss: 0.4993\n",
      "Epoch 127/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7494 - loss: 0.5148\n",
      "Epoch 128/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7586 - loss: 0.5117\n",
      "Epoch 129/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7588 - loss: 0.5114\n",
      "Epoch 130/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7431 - loss: 0.5179\n",
      "Epoch 131/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7815 - loss: 0.4825\n",
      "Epoch 132/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7419 - loss: 0.5296\n",
      "Epoch 133/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.7810 - loss: 0.4822\n",
      "Epoch 134/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.7390 - loss: 0.5291\n",
      "Epoch 135/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7599 - loss: 0.4864\n",
      "Epoch 136/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7246 - loss: 0.5250\n",
      "Epoch 137/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7876 - loss: 0.4781\n",
      "Epoch 138/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7930 - loss: 0.4572\n",
      "Epoch 139/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7351 - loss: 0.5213\n",
      "Epoch 140/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7810 - loss: 0.4708\n",
      "Epoch 141/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7583 - loss: 0.5100\n",
      "Epoch 142/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7706 - loss: 0.4872\n",
      "Epoch 143/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7822 - loss: 0.4716\n",
      "Epoch 144/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7414 - loss: 0.5106\n",
      "Epoch 145/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7645 - loss: 0.4824\n",
      "Epoch 146/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7909 - loss: 0.4714\n",
      "Epoch 147/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.7673 - loss: 0.4887\n",
      "Epoch 148/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.7727 - loss: 0.4901\n",
      "Epoch 149/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.7914 - loss: 0.4522\n",
      "Epoch 150/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7805 - loss: 0.4712\n",
      "Epoch 151/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8050 - loss: 0.4466\n",
      "Epoch 152/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7680 - loss: 0.4754\n",
      "Epoch 153/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.8004 - loss: 0.4467\n",
      "Epoch 154/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7604 - loss: 0.5190\n",
      "Epoch 155/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7660 - loss: 0.5029\n",
      "Epoch 156/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7748 - loss: 0.4933\n",
      "Epoch 157/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7560 - loss: 0.5310\n",
      "Epoch 158/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7780 - loss: 0.4791\n",
      "Epoch 159/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7274 - loss: 0.5179\n",
      "Epoch 160/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7587 - loss: 0.4915\n",
      "Epoch 161/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7583 - loss: 0.5310\n",
      "Epoch 162/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7392 - loss: 0.5270\n",
      "Epoch 163/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7512 - loss: 0.5063\n",
      "Epoch 164/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7541 - loss: 0.5315\n",
      "Epoch 165/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7846 - loss: 0.4827\n",
      "Epoch 166/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7670 - loss: 0.5001\n",
      "Epoch 167/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7713 - loss: 0.4677\n",
      "Epoch 168/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7672 - loss: 0.5055\n",
      "Epoch 169/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7283 - loss: 0.5348\n",
      "Epoch 170/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7779 - loss: 0.5013\n",
      "Epoch 171/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7670 - loss: 0.5070\n",
      "Epoch 172/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7427 - loss: 0.5132\n",
      "Epoch 173/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7586 - loss: 0.4685\n",
      "Epoch 174/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7921 - loss: 0.4434\n",
      "Epoch 175/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7725 - loss: 0.4820\n",
      "Epoch 176/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7368 - loss: 0.5107\n",
      "Epoch 177/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7775 - loss: 0.4780\n",
      "Epoch 178/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.7772 - loss: 0.4826\n",
      "Epoch 179/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.7970 - loss: 0.4601\n",
      "Epoch 180/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7865 - loss: 0.4752\n",
      "Epoch 181/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7734 - loss: 0.4673\n",
      "Epoch 182/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7923 - loss: 0.4488\n",
      "Epoch 183/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7555 - loss: 0.4808\n",
      "Epoch 184/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step - accuracy: 0.7705 - loss: 0.4665\n",
      "Epoch 185/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7908 - loss: 0.4835\n",
      "Epoch 186/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7667 - loss: 0.4807\n",
      "Epoch 187/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8084 - loss: 0.4817\n",
      "Epoch 188/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7711 - loss: 0.4756\n",
      "Epoch 189/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7446 - loss: 0.4919\n",
      "Epoch 190/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7846 - loss: 0.4805\n",
      "Epoch 191/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7773 - loss: 0.4925\n",
      "Epoch 192/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7856 - loss: 0.4883\n",
      "Epoch 193/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7717 - loss: 0.5084\n",
      "Epoch 194/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7975 - loss: 0.4536\n",
      "Epoch 195/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7555 - loss: 0.5019\n",
      "Epoch 196/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7592 - loss: 0.4938\n",
      "Epoch 197/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7850 - loss: 0.4881\n",
      "Epoch 198/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7839 - loss: 0.4592\n",
      "Epoch 199/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.7771 - loss: 0.4732\n",
      "Epoch 200/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7983 - loss: 0.4758\n",
      "Epoch 201/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7828 - loss: 0.4797\n",
      "Epoch 202/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.8037 - loss: 0.4465\n",
      "Epoch 203/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7825 - loss: 0.4866\n",
      "Epoch 204/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7976 - loss: 0.4473\n",
      "Epoch 205/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7680 - loss: 0.4997\n",
      "Epoch 206/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7681 - loss: 0.4952\n",
      "Epoch 207/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8118 - loss: 0.4681\n",
      "Epoch 208/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7869 - loss: 0.4849\n",
      "Epoch 209/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7887 - loss: 0.4648\n",
      "Epoch 210/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8045 - loss: 0.4394\n",
      "Epoch 211/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7875 - loss: 0.4784\n",
      "Epoch 212/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8024 - loss: 0.4482\n",
      "Epoch 213/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7667 - loss: 0.4782\n",
      "Epoch 214/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7739 - loss: 0.4950\n",
      "Epoch 215/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7927 - loss: 0.4792\n",
      "Epoch 216/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.8066 - loss: 0.4749\n",
      "Epoch 217/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7865 - loss: 0.4732\n",
      "Epoch 218/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7784 - loss: 0.4661\n",
      "Epoch 219/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7648 - loss: 0.4881\n",
      "Epoch 220/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7582 - loss: 0.5048\n",
      "Epoch 221/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7674 - loss: 0.4863\n",
      "Epoch 222/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7908 - loss: 0.4668\n",
      "Epoch 223/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7675 - loss: 0.4956\n",
      "Epoch 224/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7977 - loss: 0.4721\n",
      "Epoch 225/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8012 - loss: 0.4796\n",
      "Epoch 226/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.7776 - loss: 0.4755\n",
      "Epoch 227/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.7806 - loss: 0.4865\n",
      "Epoch 228/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7689 - loss: 0.4762\n",
      "Epoch 229/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.8010 - loss: 0.4586\n",
      "Epoch 230/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8047 - loss: 0.4579\n",
      "Epoch 231/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7865 - loss: 0.4797\n",
      "Epoch 232/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8055 - loss: 0.4529\n",
      "Epoch 233/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7909 - loss: 0.4635\n",
      "Epoch 234/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7752 - loss: 0.4807\n",
      "Epoch 235/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7643 - loss: 0.4848\n",
      "Epoch 236/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7960 - loss: 0.4756\n",
      "Epoch 237/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7926 - loss: 0.4750\n",
      "Epoch 238/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.7848 - loss: 0.4718\n",
      "Epoch 239/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7777 - loss: 0.4738\n",
      "Epoch 240/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8047 - loss: 0.4578\n",
      "Epoch 241/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.7896 - loss: 0.4647\n",
      "Epoch 242/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7968 - loss: 0.4455\n",
      "Epoch 243/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7977 - loss: 0.4535\n",
      "Epoch 244/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7857 - loss: 0.4812\n",
      "Epoch 245/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7715 - loss: 0.4773\n",
      "Epoch 246/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7661 - loss: 0.4918\n",
      "Epoch 247/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.7768 - loss: 0.5024\n",
      "Epoch 248/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7774 - loss: 0.4899\n",
      "Epoch 249/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8044 - loss: 0.4595\n",
      "Epoch 250/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7644 - loss: 0.4919\n",
      "Epoch 251/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7808 - loss: 0.4906\n",
      "Epoch 252/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7818 - loss: 0.4787\n",
      "Epoch 253/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.8086 - loss: 0.4433\n",
      "Epoch 254/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7995 - loss: 0.4333\n",
      "Epoch 255/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.7779 - loss: 0.4691\n",
      "Epoch 256/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7886 - loss: 0.4570\n",
      "Epoch 257/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7853 - loss: 0.4608\n",
      "Epoch 258/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7856 - loss: 0.4706\n",
      "Epoch 259/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7556 - loss: 0.4896\n",
      "Epoch 260/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7911 - loss: 0.4660\n",
      "Epoch 261/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7803 - loss: 0.4895\n",
      "Epoch 262/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8014 - loss: 0.4499\n",
      "Epoch 263/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7703 - loss: 0.4995\n",
      "Epoch 264/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.8101 - loss: 0.4635\n",
      "Epoch 265/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - accuracy: 0.8255 - loss: 0.4389\n",
      "Epoch 266/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8109 - loss: 0.4350\n",
      "Epoch 267/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8040 - loss: 0.4696\n",
      "Epoch 268/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7886 - loss: 0.4704\n",
      "Epoch 269/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8137 - loss: 0.4400\n",
      "Epoch 270/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7992 - loss: 0.4569\n",
      "Epoch 271/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7787 - loss: 0.4686\n",
      "Epoch 272/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7994 - loss: 0.4504\n",
      "Epoch 273/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7793 - loss: 0.4633\n",
      "Epoch 274/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 0.8134 - loss: 0.4516\n",
      "Epoch 275/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7768 - loss: 0.4692\n",
      "Epoch 276/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7906 - loss: 0.4578\n",
      "Epoch 277/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7961 - loss: 0.4518\n",
      "Epoch 278/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7636 - loss: 0.4957\n",
      "Epoch 279/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7935 - loss: 0.4756\n",
      "Epoch 280/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.8031 - loss: 0.4606\n",
      "Epoch 281/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8053 - loss: 0.4485\n",
      "Epoch 282/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.8158 - loss: 0.4314\n",
      "Epoch 283/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7837 - loss: 0.4574\n",
      "Epoch 284/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7911 - loss: 0.4667\n",
      "Epoch 285/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7962 - loss: 0.4606\n",
      "Epoch 286/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7866 - loss: 0.4807\n",
      "Epoch 287/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8065 - loss: 0.4537\n",
      "Epoch 288/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8025 - loss: 0.4344\n",
      "Epoch 289/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7856 - loss: 0.4720\n",
      "Epoch 290/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7980 - loss: 0.4527\n",
      "Epoch 291/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7981 - loss: 0.4442\n",
      "Epoch 292/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7751 - loss: 0.4772\n",
      "Epoch 293/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8024 - loss: 0.4715\n",
      "Epoch 294/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7784 - loss: 0.4664\n",
      "Epoch 295/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7879 - loss: 0.4853\n",
      "Epoch 296/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7935 - loss: 0.4776\n",
      "Epoch 297/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8001 - loss: 0.4478\n",
      "Epoch 298/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7821 - loss: 0.4795\n",
      "Epoch 299/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7971 - loss: 0.4789\n",
      "Epoch 300/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7678 - loss: 0.4767\n",
      "Epoch 301/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7789 - loss: 0.5105\n",
      "Epoch 302/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7689 - loss: 0.4888\n",
      "Epoch 303/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7730 - loss: 0.4939\n",
      "Epoch 304/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.7943 - loss: 0.4786\n",
      "Epoch 305/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8012 - loss: 0.4761\n",
      "Epoch 306/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8030 - loss: 0.4642\n",
      "Epoch 307/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7483 - loss: 0.5051\n",
      "Epoch 308/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7985 - loss: 0.4600\n",
      "Epoch 309/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7948 - loss: 0.4619\n",
      "Epoch 310/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8028 - loss: 0.4537\n",
      "Epoch 311/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7744 - loss: 0.4773\n",
      "Epoch 312/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7626 - loss: 0.5224\n",
      "Epoch 313/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7905 - loss: 0.4742\n",
      "Epoch 314/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8122 - loss: 0.4547\n",
      "Epoch 315/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7926 - loss: 0.4630\n",
      "Epoch 316/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7895 - loss: 0.4660\n",
      "Epoch 317/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7681 - loss: 0.5034\n",
      "Epoch 318/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.8081 - loss: 0.4212\n",
      "Epoch 319/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7938 - loss: 0.4556\n",
      "Epoch 320/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7778 - loss: 0.4786\n",
      "Epoch 321/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7766 - loss: 0.4790\n",
      "Epoch 322/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7697 - loss: 0.5000\n",
      "Epoch 323/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7754 - loss: 0.4918\n",
      "Epoch 324/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7989 - loss: 0.4745\n",
      "Epoch 325/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.8175 - loss: 0.4479\n",
      "Epoch 326/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7985 - loss: 0.4692\n",
      "Epoch 327/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7838 - loss: 0.4782\n",
      "Epoch 328/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7652 - loss: 0.4788\n",
      "Epoch 329/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7854 - loss: 0.4764\n",
      "Epoch 330/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.7872 - loss: 0.4879\n",
      "Epoch 331/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7506 - loss: 0.5073\n",
      "Epoch 332/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7559 - loss: 0.4980\n",
      "Epoch 333/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.8085 - loss: 0.4339\n",
      "Epoch 334/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 0.7878 - loss: 0.4800\n",
      "Epoch 335/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7951 - loss: 0.4509\n",
      "Epoch 336/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.8041 - loss: 0.4321\n",
      "Epoch 337/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7963 - loss: 0.4669\n",
      "Epoch 338/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7923 - loss: 0.4692\n",
      "Epoch 339/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7938 - loss: 0.4645\n",
      "Epoch 340/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8036 - loss: 0.4384\n",
      "Epoch 341/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.8166 - loss: 0.4328\n",
      "Epoch 342/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7958 - loss: 0.4840\n",
      "Epoch 343/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8118 - loss: 0.4451\n",
      "Epoch 344/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7893 - loss: 0.4588\n",
      "Epoch 345/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7874 - loss: 0.4780\n",
      "Epoch 346/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7731 - loss: 0.4771\n",
      "Epoch 347/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7718 - loss: 0.4772\n",
      "Epoch 348/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8014 - loss: 0.4492\n",
      "Epoch 349/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7933 - loss: 0.4705\n",
      "Epoch 350/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8240 - loss: 0.4289\n",
      "Epoch 351/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7705 - loss: 0.4955\n",
      "Epoch 352/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7831 - loss: 0.4759\n",
      "Epoch 353/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7740 - loss: 0.4885\n",
      "Epoch 354/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7556 - loss: 0.4994\n",
      "Epoch 355/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7691 - loss: 0.4634\n",
      "Epoch 356/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - accuracy: 0.7607 - loss: 0.5049\n",
      "Epoch 357/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8025 - loss: 0.4411\n",
      "Epoch 358/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7947 - loss: 0.4567\n",
      "Epoch 359/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7911 - loss: 0.4741\n",
      "Epoch 360/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7920 - loss: 0.4660\n",
      "Epoch 361/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8225 - loss: 0.4291\n",
      "Epoch 362/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.7936 - loss: 0.4804\n",
      "Epoch 363/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7739 - loss: 0.4624\n",
      "Epoch 364/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.8126 - loss: 0.4453\n",
      "Epoch 365/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7996 - loss: 0.4663\n",
      "Epoch 366/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7661 - loss: 0.4820\n",
      "Epoch 367/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7849 - loss: 0.4729\n",
      "Epoch 368/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7713 - loss: 0.5098\n",
      "Epoch 369/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8263 - loss: 0.4349\n",
      "Epoch 370/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.7703 - loss: 0.5096\n",
      "Epoch 371/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.7807 - loss: 0.4904\n",
      "Epoch 372/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7966 - loss: 0.4675\n",
      "Epoch 373/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8125 - loss: 0.4632\n",
      "Epoch 374/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7667 - loss: 0.4816\n",
      "Epoch 375/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.8055 - loss: 0.4505\n",
      "Epoch 376/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7629 - loss: 0.5031\n",
      "Epoch 377/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7777 - loss: 0.4874\n",
      "Epoch 378/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7901 - loss: 0.4549\n",
      "Epoch 379/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7666 - loss: 0.4831\n",
      "Epoch 380/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7972 - loss: 0.4627\n",
      "Epoch 381/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8063 - loss: 0.4483\n",
      "Epoch 382/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.7820 - loss: 0.4835\n",
      "Epoch 383/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8002 - loss: 0.4549\n",
      "Epoch 384/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7836 - loss: 0.4640\n",
      "Epoch 385/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.7742 - loss: 0.4776\n",
      "Epoch 386/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7849 - loss: 0.4688\n",
      "Epoch 387/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8065 - loss: 0.4580\n",
      "Epoch 388/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7879 - loss: 0.4583\n",
      "Epoch 389/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7892 - loss: 0.4394\n",
      "Epoch 390/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7968 - loss: 0.4529\n",
      "Epoch 391/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7843 - loss: 0.4772\n",
      "Epoch 392/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7987 - loss: 0.4655\n",
      "Epoch 393/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7952 - loss: 0.4477\n",
      "Epoch 394/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7922 - loss: 0.4803\n",
      "Epoch 395/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7774 - loss: 0.4701\n",
      "Epoch 396/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7937 - loss: 0.4548\n",
      "Epoch 397/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.8041 - loss: 0.4708\n",
      "Epoch 398/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.8106 - loss: 0.4558\n",
      "Epoch 399/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7738 - loss: 0.5217\n",
      "Epoch 400/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8005 - loss: 0.4768\n",
      "Epoch 401/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7898 - loss: 0.4734\n",
      "Epoch 402/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.8008 - loss: 0.4618\n",
      "Epoch 403/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7846 - loss: 0.4972\n",
      "Epoch 404/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.8009 - loss: 0.4354\n",
      "Epoch 405/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7878 - loss: 0.4625\n",
      "Epoch 406/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7718 - loss: 0.4753\n",
      "Epoch 407/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7890 - loss: 0.4999\n",
      "Epoch 408/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.8053 - loss: 0.4455\n",
      "Epoch 409/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7973 - loss: 0.4535\n",
      "Epoch 410/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7961 - loss: 0.4608\n",
      "Epoch 411/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.8000 - loss: 0.4522\n",
      "Epoch 412/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8082 - loss: 0.4660\n",
      "Epoch 413/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7783 - loss: 0.4804\n",
      "Epoch 414/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8003 - loss: 0.4636\n",
      "Epoch 415/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.8067 - loss: 0.4582\n",
      "Epoch 416/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.8022 - loss: 0.4619\n",
      "Epoch 417/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7735 - loss: 0.4892\n",
      "Epoch 418/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.8025 - loss: 0.4689\n",
      "Epoch 419/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.8174 - loss: 0.4226\n",
      "Epoch 420/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7925 - loss: 0.4384\n",
      "Epoch 421/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7780 - loss: 0.4851\n",
      "Epoch 422/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.7697 - loss: 0.4864\n",
      "Epoch 423/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7927 - loss: 0.4487\n",
      "Epoch 424/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.7956 - loss: 0.4536\n",
      "Epoch 425/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.7970 - loss: 0.4634\n",
      "Epoch 426/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7908 - loss: 0.4784\n",
      "Epoch 427/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8016 - loss: 0.4556\n",
      "Epoch 428/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.7958 - loss: 0.4448\n",
      "Epoch 429/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7564 - loss: 0.5005\n",
      "Epoch 430/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.7967 - loss: 0.4727\n",
      "Epoch 431/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7973 - loss: 0.4624\n",
      "Epoch 432/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8054 - loss: 0.4265\n",
      "Epoch 433/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7905 - loss: 0.4550\n",
      "Epoch 434/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7888 - loss: 0.4633\n",
      "Epoch 435/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7995 - loss: 0.4558\n",
      "Epoch 436/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - accuracy: 0.8091 - loss: 0.4639\n",
      "Epoch 437/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.7922 - loss: 0.4594\n",
      "Epoch 438/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7771 - loss: 0.5050\n",
      "Epoch 439/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8111 - loss: 0.4505\n",
      "Epoch 440/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7795 - loss: 0.4712\n",
      "Epoch 441/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.7840 - loss: 0.5077\n",
      "Epoch 442/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7969 - loss: 0.4537\n",
      "Epoch 443/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7880 - loss: 0.4695\n",
      "Epoch 444/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.7807 - loss: 0.4995\n",
      "Epoch 445/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - accuracy: 0.7855 - loss: 0.4767\n",
      "Epoch 446/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7986 - loss: 0.4677\n",
      "Epoch 447/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7860 - loss: 0.4761\n",
      "Epoch 448/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7872 - loss: 0.4576\n",
      "Epoch 449/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.7753 - loss: 0.4806\n",
      "Epoch 450/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7680 - loss: 0.4916\n",
      "Epoch 451/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.7762 - loss: 0.4701\n",
      "Epoch 452/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - accuracy: 0.7873 - loss: 0.4694\n",
      "Epoch 453/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.8039 - loss: 0.4579\n",
      "Epoch 454/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.7930 - loss: 0.4567\n",
      "Epoch 455/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.8114 - loss: 0.4234\n",
      "Epoch 456/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.8162 - loss: 0.4442\n",
      "Epoch 457/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.7849 - loss: 0.4889\n",
      "Epoch 458/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8215 - loss: 0.4263\n",
      "Epoch 459/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7993 - loss: 0.4444\n",
      "Epoch 460/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7762 - loss: 0.4546\n",
      "Epoch 461/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.8057 - loss: 0.4545\n",
      "Epoch 462/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.8003 - loss: 0.4552\n",
      "Epoch 463/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7907 - loss: 0.4683\n",
      "Epoch 464/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7658 - loss: 0.4851\n",
      "Epoch 465/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7722 - loss: 0.4800\n",
      "Epoch 466/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7822 - loss: 0.4610\n",
      "Epoch 467/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7928 - loss: 0.4552\n",
      "Epoch 468/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8083 - loss: 0.4704\n",
      "Epoch 469/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7681 - loss: 0.4777\n",
      "Epoch 470/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.8084 - loss: 0.4536\n",
      "Epoch 471/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7832 - loss: 0.4713\n",
      "Epoch 472/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.7937 - loss: 0.4604\n",
      "Epoch 473/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7783 - loss: 0.4499\n",
      "Epoch 474/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.7949 - loss: 0.4531\n",
      "Epoch 475/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.8008 - loss: 0.4524\n",
      "Epoch 476/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.8092 - loss: 0.4590\n",
      "Epoch 477/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.8111 - loss: 0.4608\n",
      "Epoch 478/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8029 - loss: 0.4562\n",
      "Epoch 479/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7945 - loss: 0.4648\n",
      "Epoch 480/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7977 - loss: 0.4591\n",
      "Epoch 481/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7968 - loss: 0.4649\n",
      "Epoch 482/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.8027 - loss: 0.4584\n",
      "Epoch 483/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7976 - loss: 0.4518\n",
      "Epoch 484/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.7717 - loss: 0.4814\n",
      "Epoch 485/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7751 - loss: 0.4851\n",
      "Epoch 486/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.8078 - loss: 0.4710\n",
      "Epoch 487/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7980 - loss: 0.4798\n",
      "Epoch 488/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7766 - loss: 0.4763\n",
      "Epoch 489/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7783 - loss: 0.4497\n",
      "Epoch 490/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.7829 - loss: 0.4858\n",
      "Epoch 491/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.8147 - loss: 0.4566\n",
      "Epoch 492/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.8036 - loss: 0.4545\n",
      "Epoch 493/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.8004 - loss: 0.4540\n",
      "Epoch 494/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.7985 - loss: 0.4538\n",
      "Epoch 495/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.7857 - loss: 0.4559\n",
      "Epoch 496/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.7924 - loss: 0.4621\n",
      "Epoch 497/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.7725 - loss: 0.4908\n",
      "Epoch 498/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 0.7760 - loss: 0.5028\n",
      "Epoch 499/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.7795 - loss: 0.4669\n",
      "Epoch 500/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.8018 - loss: 0.4637\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=16, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b93d3368",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived':y_pred.flatten()})\n",
    "out.to_csv('model3.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5eca7a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived':y_pred.flatten()})\n",
    "out.to_csv('model4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6355c609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5de5da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.4922 - loss: 0.9342 \n",
      "Epoch 2/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.5998 - loss: 0.7401\n",
      "Epoch 3/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - accuracy: 0.5891 - loss: 0.7412\n",
      "Epoch 4/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.6087 - loss: 0.7099\n",
      "Epoch 5/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - accuracy: 0.5850 - loss: 0.7287\n",
      "Epoch 6/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.5864 - loss: 0.7035\n",
      "Epoch 7/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.5744 - loss: 0.7227\n",
      "Epoch 8/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.6040 - loss: 0.6855\n",
      "Epoch 9/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.6257 - loss: 0.6571\n",
      "Epoch 10/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.6035 - loss: 0.6807\n",
      "Epoch 11/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 0.6571 - loss: 0.6486\n",
      "Epoch 12/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.6418 - loss: 0.6489\n",
      "Epoch 13/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 0.6509 - loss: 0.6431\n",
      "Epoch 14/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 0.6616 - loss: 0.6343\n",
      "Epoch 15/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6398 - loss: 0.6563\n",
      "Epoch 16/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6711 - loss: 0.6306\n",
      "Epoch 17/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.6530 - loss: 0.6444\n",
      "Epoch 18/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6655 - loss: 0.6239\n",
      "Epoch 19/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.6589 - loss: 0.6278\n",
      "Epoch 20/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.6382 - loss: 0.6493\n",
      "Epoch 21/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6817 - loss: 0.5990\n",
      "Epoch 22/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.6825 - loss: 0.6349\n",
      "Epoch 23/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.6666 - loss: 0.6122\n",
      "Epoch 24/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7025 - loss: 0.6173\n",
      "Epoch 25/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - accuracy: 0.6989 - loss: 0.5920\n",
      "Epoch 26/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.6781 - loss: 0.6189\n",
      "Epoch 27/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514us/step - accuracy: 0.7033 - loss: 0.5794\n",
      "Epoch 28/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.6859 - loss: 0.6108\n",
      "Epoch 29/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - accuracy: 0.6986 - loss: 0.5798\n",
      "Epoch 30/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.7019 - loss: 0.5850\n",
      "Epoch 31/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7011 - loss: 0.5860\n",
      "Epoch 32/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.7176 - loss: 0.5581\n",
      "Epoch 33/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 0.6759 - loss: 0.5951\n",
      "Epoch 34/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7083 - loss: 0.5860\n",
      "Epoch 35/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 0.7409 - loss: 0.5446\n",
      "Epoch 36/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.7352 - loss: 0.5544\n",
      "Epoch 37/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.7162 - loss: 0.5443\n",
      "Epoch 38/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7324 - loss: 0.5502\n",
      "Epoch 39/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.7457 - loss: 0.5365\n",
      "Epoch 40/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.7024 - loss: 0.5799\n",
      "Epoch 41/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 0.7455 - loss: 0.5353\n",
      "Epoch 42/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7789 - loss: 0.5287\n",
      "Epoch 43/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.7317 - loss: 0.5587\n",
      "Epoch 44/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7582 - loss: 0.5162\n",
      "Epoch 45/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - accuracy: 0.7325 - loss: 0.5264\n",
      "Epoch 46/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.6735 - loss: 0.6238\n",
      "Epoch 47/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.6799 - loss: 0.6095\n",
      "Epoch 48/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.6975 - loss: 0.5919\n",
      "Epoch 49/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - accuracy: 0.7012 - loss: 0.5762\n",
      "Epoch 50/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step - accuracy: 0.7143 - loss: 0.5675\n",
      "Epoch 51/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564us/step - accuracy: 0.7166 - loss: 0.5941\n",
      "Epoch 52/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.6995 - loss: 0.5751\n",
      "Epoch 53/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 0.7077 - loss: 0.5587\n",
      "Epoch 54/500\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 0.7476 - loss: 0.5101\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='loss',  \n",
    "    patience=10,         \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "\n",
    "x_res = Dense(64, activation='relu')(x)\n",
    "x_res = BatchNormalization()(x_res)\n",
    "x_res = Dropout(0.3)(x_res)\n",
    "x = Add()([x, x_res])  \n",
    "\n",
    "\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=500, \n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop],  \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ad13f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fcb72dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pd.DataFrame({'PassengerId': X_test.PassengerId, 'Survived':y_pred.flatten()})\n",
    "out.to_csv('model5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888a2285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "livemea-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
